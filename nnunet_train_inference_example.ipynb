{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9974ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T21:00:48.008269574Z",
     "start_time": "2024-03-25T21:00:48.002479279Z"
    }
   },
   "outputs": [],
   "source": [
    "#requires you to pip install nnunetv2 and some others\n",
    "#for install details see: https://github.com/MIC-DKFZ/nnUNet\n",
    "import nnunetv2\n",
    "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('path_to_dir_w_scripts') #not required if in the same dir\n",
    "from nnunet_utils.utils import np2sitk, set_env_nnunet, write_envlines_nnunet, assign_trainjobs_to_gpus\n",
    "from nnunet_utils.preprocess import write_as_nnunet, nnunet_directory_structure, preprocess_data\n",
    "from nnunet_utils.run import train_single_model, nnunet_train_shell\n",
    "\n",
    "#root in what folder your nnunet data is stored\n",
    "root = '/home/hvv/Documents/nnunet'\n",
    "datano = '512' #this is an arbitrary number you can choose --> should not be the same as other studies\n",
    "project_name = 'nameyourproject'\n",
    "task = 'Task{}_nameyourproject'.format(datano) #this is also something you choose\n",
    "datasetID = 'Dataset{}_nameyourproject'.format(datano)\n",
    "#where your train (or test) data is stored\n",
    "p_dir = os.path.join(root,'nnUNet_raw',datasetID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8573f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over your dataset\n",
    "#create a training images and label folder\n",
    "\n",
    "#write your own script here loading an IMG and GT every iteration\n",
    "#something like:\n",
    "\n",
    "p_data = 'path_to_source_img_lbl' #subfolders with IDs and scan and gt files\n",
    "for ID in os.listdir(p_data):\n",
    "    pid = os.path.join(p_data,ID)\n",
    "    \n",
    "    p_img = os.path.join(pid,'scan.nii.gz')\n",
    "    p_gt = os.path.join(pid,'gt.nii.gz')\n",
    "    \n",
    "    IMG = sitk.ReadImage(p_img)\n",
    "    GT = sitk.ReadImage(p_gt)\n",
    "    #this example should be applied to all your training images-labels\n",
    "    #you can also use this to preprocess your test set\n",
    "    #this is however not required\n",
    "    write_as_nnunet(IMG, GT, p_dir, ID)\n",
    "#IMG: sitk.Image with the CT/MR scan \n",
    "#GT: sitk Image with corresponding ground truth segmentations\n",
    "#p_dir: where the imagesTr and labelsTr should be stored\n",
    "#ID: ID number (including dataset name) for identification of IMG-GT pairs\n",
    "\n",
    "#sanity check to see if all images have labels\n",
    "root_images = os.path.join(p_dir,'imagesTr')\n",
    "root_gt = os.path.join(p_dir, 'labelsTr')\n",
    "img_lbl_paircount(root_images, root_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72a1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates the nnunet directory structure inside the root folder\n",
    "nnunet_directory_structure(root,version=2)\n",
    "#make sure your data imagesTr and labelsTr folders are pasted in nnUnet_raw folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the scans have to be preprocessed for training\n",
    "#this is something specifically required by nnUnet\n",
    "#this may take a while, if it fails run again\n",
    "preprocess_data(root, \n",
    "                datano=datano,\n",
    "                datasetID=datasetID, #or task name in old version\n",
    "                dataset_name=project_name,\n",
    "                modalities=['BL_MR_FLAIR'] #should be a list representing each input channel --> important: should include MR or CT\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e13365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are two options to instantiate training models\n",
    "#1) one-by-one: \n",
    "#train models consecutively for each fold --> run this manually 5 times\n",
    "train_single_model(gpu=0, #each pc with a single gpu has number 0, selecting another gpu on a server is possible\n",
    "                   datasetID=datasetID, #defined above\n",
    "                   resolution='3d_fullres', #can select nnUnet config: ['2d','3d_fullres','3d_lowres', '3d_cascade_fullres'] \n",
    "                   fold=0, #start with the first fold (number 0)\n",
    "                  )\n",
    "\n",
    "\n",
    "#2) parallel across gpus: \n",
    "#2a) Create mapping: which GPU does what\n",
    "#Assign jobs to gpus: this is an equal distribution script\n",
    "#it can be wise to first check gpu availability \n",
    "#and then make your own dictionary with distribution dictionary\n",
    "#returns a dictionary with per entry:\n",
    "# gpu_number:[job1, job2] \n",
    "#where each job:\n",
    "#(resolution, fold_number)\n",
    "gpu_dct = assign_trainjobs_to_gpus(num_gpus, #total number of GPUs available OR a list of available GPU numbers\n",
    "                           num_folds, #number of folds to train (default=5)\n",
    "                           resolutions #list of resolutions, any from ['2d','3d_fullres','3d_lowres', '3d_cascade_fullres'] \n",
    "                                )\n",
    "\n",
    "\n",
    "#2b) Create shell script\n",
    "#create a train_job.sh shell script to run multiple folds at the same time\n",
    "#the shell script manages parallel computation across gpus\n",
    "nnunet_train_shell(datasetID=datasetID, #defined above\n",
    "                    root=root,#defined above\n",
    "                    conda_env='/path/to/miniconda3/envs/nnunetv2', #path to your environment\n",
    "                    gpu_res_fold_dct=gpu_dct, #is dictionary mapping resolutions, folds and gpus (see above)\n",
    "                    version=2)\n",
    "\n",
    "#2c) Run shell script\n",
    "#Last thing: run the shell script on the server\n",
    "#ssh to server, cd to nnunet folder then: bash train_job.sh\n",
    "#to make sure the server stays running when you close your pc\n",
    "#use tmux: https://tmuxcheatsheet.com/ and https://hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6305db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference: to predict segmentations using a trained model\n",
    "#After your model is trained these scripts can be used on new cases\n",
    "#there are three ways\n",
    "#1) Run in the python script line by line\n",
    "from nnunet_utils.infv2 import init_predictor, nnunetv2_get_props, nnunetv2_predict\n",
    "\n",
    "model_path = os.path.join(root,'nnUNet_trained_models', datasetID,'nnUNetTrainer__nnUNetPlans__3d_fullres')\n",
    "predictor = init_predictor(model_path)\n",
    "\n",
    "p_data = 'your_test_set_folder'\n",
    "\n",
    "for ID in tqdm(os.listdir(p_data)):\n",
    "    pid = os.path.join(p_crisp,ID)\n",
    "    #input file\n",
    "    file = os.path.join(pid,'scan.nii.gz')\n",
    "    \n",
    "    #output nifti segmentation and also probability output as npy\n",
    "    p_vseg_out = os.path.join(pid,'vesselseg.nii.gz')\n",
    "    p_npy_vseg = os.path.join(pid,'vesselseg')\n",
    "    \n",
    "    #sanity check to not run the same stuff twice\n",
    "    if os.path.exists(p_vseg_out) and os.path.exists(p_npy_vseg+'.npy'):\n",
    "        continue\n",
    "    #running this for loop can take long\n",
    "    #so a try-except to prevent stopping somewhere in the middle\n",
    "    try:\n",
    "        mra = sitk.ReadImage(file)\n",
    "        props = nnunetv2_get_props(mra)\n",
    "        mra_inp = np.expand_dims(sitk.GetArrayFromImage(mra),0)\n",
    "        seg = nnunetv2_predict(mra_inp,props,predictor, return_probabilities=True)\n",
    "\n",
    "        sitk.WriteImage(np2sitk(seg[0],mra),p_vseg_out)\n",
    "\n",
    "        np.save(p_npy_vseg,seg[1])\n",
    "    except:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Create a file with all input images similar to the imagesTr (but now imagesTs)\n",
    "#and run it in a batch at once\n",
    "from nnunet_utils.run import nnunet_inference_on_dir\n",
    "\n",
    "#first put all scans in the test folder:\n",
    "#nnUNet_raw/DatasetID/imagesTs\n",
    "test_img_dir = os.path.join(p_dir,'imagesTs')\n",
    "for ID in os.listdir(p_data):\n",
    "    pid = os.path.join(p_data,ID)\n",
    "    p_img = os.path.join(pid,'scan_test.nii.gz')\n",
    "    #this function copies using shutil (=really fast)\n",
    "    copy_inference_image(p_img, test_img_dir)\n",
    "    #as an alternative you can read with sitk and write\n",
    "    #which is slower but still ok in speed\n",
    "    \n",
    "#with the data in the right order\n",
    "#it is now possible to run the inference commands\n",
    "model_path = os.path.join(root,'nnUNet_trained_models', datasetID,'nnUNetTrainer__nnUNetPlans__3d_fullres')\n",
    "seg_test_pred_dir = os.path.join(p_dir,'predictions')\n",
    "if not os.path.exists(seg_test_pred_dir):\n",
    "    os.makedirs(seg_test_pred_dir)\n",
    "    \n",
    "nnunet_inference_on_dir(model_path=model_path, #path to the trained folds\n",
    "                        dir_input_images=test_img_dir, #where the imagesTs (inference images) are stored\n",
    "                        dir_output_seg=seg_test_pred_dir, #where you want to store the predictions\n",
    "                        resolution='fullres', #can select nnUnet config (must correspond with model_path): ['2d','3d_fullres','3d_lowres', '3d_cascade_fullres'] \n",
    "                        save_probs=True #if you want predicted probabilities\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6026d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) For large datasets it can be useful to run inference on multiple GPUs\n",
    "#Similar to training: create a gpu_dct defining the distribution\n",
    "#of images across GPUs and run it using a shell script\n",
    "from nnunet_utils.run import nnunetv2_inference_shell\n",
    "\n",
    "#input parameters\n",
    "path_images_in = 'directory/with/inference/images'\n",
    "path_segs_out = 'directory/to/output/segmentation/folder'\n",
    "p_model = 'path/to/nnunet/model/nnUNet_trained_models/Datasetxxx_name/nnUNetTrainer__nnUNetPlans__3d_fullres'\n",
    "conda_env = 'miniconda3/envs/nnunetv2' #contains pip installed nnunetv2\n",
    "root = 'root/to/nnunet/dir/to/set/path/variables'\n",
    "\n",
    "gpu_dct = gpu_distributed_inference(images=path_images_in, #input images for inference\n",
    "                                      num_gpus=1, #int or list defining available gpus\n",
    "                                      resolutions=['fullres_3d'],\n",
    "                                      separate_folders=False, #if True GPU batches of images are copied to separate folders\n",
    "                                      seg_dir=None, #pass path_segs_out to skip certain \n",
    "                                    )\n",
    "\n",
    "job_file = nnunetv2_inference_shell(root=root,\n",
    "                                    conda_env=conda_env,\n",
    "                                    gpu_dct=gpu_dct,  # is created with utils function assign_to_gpu\n",
    "                                    path_model=p_model,\n",
    "                                    dir_output_seg=path_segs_out,\n",
    "                                    return_probabilities=True,\n",
    "                                    path_nnunet_utils='path/to/nnunet_utils',\n",
    "                                    version=2)\n",
    "print(job_file)\n",
    "#run the job_file using bash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
